import os
import fitz  # PyMuPDF
import base64
from openai import OpenAI
from pptx import Presentation
from pptx.util import Inches
import io
from PIL import Image
import torch
import torchaudio
import soundfile as sf
import numpy as np
from zonos.model import Zonos
from zonos.conditioning import make_cond_dict
from zonos.utils import DEFAULT_DEVICE as device

# 1. API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì•ˆì „í•˜ê²Œ ë¶ˆëŸ¬ì˜¤ê¸°
api_key = os.environ.get("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
client = OpenAI(api_key=api_key)

# Zonos ëª¨ë¸ ì´ˆê¸°í™” (ì „ì—­ ë³€ìˆ˜ë¡œ ê´€ë¦¬)
ZONOS_MODEL = None
SPEAKER_EMBEDDING = None


def initialize_zonos_model(model_name="Zyphra/Zonos-v0.1-transformer"):
    """Zonos ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜"""
    global ZONOS_MODEL
    if ZONOS_MODEL is None:
        print("Zonos ëª¨ë¸ì„ ë¡œë”© ì¤‘...")
        ZONOS_MODEL = Zonos.from_pretrained(model_name, device=device)
        ZONOS_MODEL.requires_grad_(False).eval()
        print("Zonos ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    return ZONOS_MODEL


def load_speaker_embedding(speaker_audio_path):
    """ìƒ˜í”Œ ì˜¤ë””ì˜¤ì—ì„œ ìŠ¤í”¼ì»¤ ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    global SPEAKER_EMBEDDING
    if SPEAKER_EMBEDDING is None and speaker_audio_path:
        print(f"ìŠ¤í”¼ì»¤ ì˜¤ë””ì˜¤ì—ì„œ ì„ë² ë”© ìƒì„± ì¤‘: {speaker_audio_path}")
        try:
            # torchaudioë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ë¡œë“œ (Gradio ë°©ì‹ê³¼ ë™ì¼)
            wav, sampling_rate = torchaudio.load(speaker_audio_path)
            
            # ìŠ¤í”¼ì»¤ ì„ë² ë”© ìƒì„±
            SPEAKER_EMBEDDING = ZONOS_MODEL.make_speaker_embedding(wav, sampling_rate)
            # bfloat16ìœ¼ë¡œ ë³€í™˜ (Gradio ë°©ì‹ê³¼ ë™ì¼)
            SPEAKER_EMBEDDING = SPEAKER_EMBEDDING.to(device, dtype=torch.bfloat16)
            print("ìŠ¤í”¼ì»¤ ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
        except Exception as e:
            print(f"torchaudio ë¡œë”© ì‹¤íŒ¨, soundfileë¡œ ì‹œë„: {e}")
            try:
                # soundfileì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ë¡œë“œ
                wav, sampling_rate = sf.read(speaker_audio_path)
                # numpy ë°°ì—´ì„ torch tensorë¡œ ë³€í™˜
                wav = torch.from_numpy(wav).float()
                # ëª¨ë…¸ ì±„ë„ë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
                if wav.dim() > 1:
                    wav = wav.mean(dim=-1)
                # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
                wav = wav.unsqueeze(0)
                
                SPEAKER_EMBEDDING = ZONOS_MODEL.make_speaker_embedding(wav, sampling_rate)
                SPEAKER_EMBEDDING = SPEAKER_EMBEDDING.to(device, dtype=torch.bfloat16)
                print("ìŠ¤í”¼ì»¤ ì„ë² ë”© ìƒì„± ì™„ë£Œ! (soundfile ì‚¬ìš©)")
            except Exception as e2:
                print(f"soundfileë¡œë„ ë¡œë”© ì‹¤íŒ¨: {e2}")
                return None
    return SPEAKER_EMBEDDING


def generate_voice_from_text(text, speaker_audio_path=None, language="en-us", output_path=None):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = initialize_zonos_model()
    
    # ìŠ¤í”¼ì»¤ ì„ë² ë”© ë¡œë“œ
    if speaker_audio_path:
        speaker_embedding = load_speaker_embedding(speaker_audio_path)
    else:
        speaker_embedding = None
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ì¸ (ë””ë²„ê¹…ìš©)
    print(f"ì²˜ë¦¬í•  ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì")
    
    # ê¸´ í…ìŠ¤íŠ¸ì˜ ê²½ìš° ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬
    if len(text) > 800:
        print(f"ê¸´ í…ìŠ¤íŠ¸ ê°ì§€ ({len(text)}ì). ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        return generate_long_text_voice(text, model, speaker_embedding, language, output_path)
    
    # Gradio ë°©ì‹ì˜ speaking_rate ê³„ì‚°
    text_length = len(text)
    
    # Gradioì—ì„œ ì‚¬ìš©í•˜ëŠ” ê³µì‹: estimated_generation_duration = 30 * len(text) / 400
    # ì´ë¥¼ ì—­ì‚°í•˜ì—¬ speaking_rate ê³„ì‚°
    estimated_duration = 30 * text_length / 400  # Gradio ë°©ì‹
    estimated_duration = max(min(estimated_duration, 30), 5)  # 5-30ì´ˆ ë²”ìœ„ë¡œ ì œí•œ
    
    # speaking_rateëŠ” ì´ˆë‹¹ ìŒì†Œ ìˆ˜ì´ë¯€ë¡œ, í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°
    # í•œêµ­ì–´ì˜ ê²½ìš° ëŒ€ëµì ìœ¼ë¡œ ê¸€ì ìˆ˜ * 1.5 = ìŒì†Œ ìˆ˜
    estimated_phonemes = text_length * 1.5
    speaking_rate = estimated_phonemes / estimated_duration
    
    # speaking_rate ë²”ìœ„ ì œí•œ (5-30)
    speaking_rate = max(min(speaking_rate, 30), 5)
    
    print(f"í…ìŠ¤íŠ¸ ê¸¸ì´: {text_length}ì, ì˜ˆìƒ ê¸¸ì´: {estimated_duration:.1f}ì´ˆ, Speaking rate: {speaking_rate:.1f}")
    
    # ì¡°ê±´ë¶€ ìƒì„± ì„¤ì • - ë³´ì´ìŠ¤ í´ë¡œë‹ ìµœì í™”
    cond_dict = make_cond_dict(
        text=text,
        speaker=speaker_embedding,
        language=language,
        device=device,
        # ë³´ì´ìŠ¤ í´ë¡œë‹ ìµœì í™” íŒŒë¼ë¯¸í„°
        pitch_std=45.0,  # ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± (Gradio ê¸°ë³¸ê°’)
        speaking_rate=speaking_rate,  # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¼ ì¡°ì •
        vqscore_8=[0.78] * 8,  # Gradio ê¸°ë³¸ê°’
        dnsmos_ovrl=4.0,  # Gradio ê¸°ë³¸ê°’
        fmax=22050.0,  # ë³´ì´ìŠ¤ í´ë¡œë‹ì— ìµœì í™”ëœ ì£¼íŒŒìˆ˜
        speaker_noised=False  # ìŠ¤í”¼ì»¤ ë…¸ì´ì¦ˆ ì œê±° ë¹„í™œì„±í™”
    )
    conditioning = model.prepare_conditioning(cond_dict)
    
    # ìŒì„± ìƒì„±
    print(f"ìŒì„± ìƒì„± ì¤‘: '{text[:50]}...'")
    codes = model.generate(conditioning)
    wavs = model.autoencoder.decode(codes).cpu()
    
    # ì˜¤ë””ì˜¤ ì €ì¥
    if output_path:
        try:
            # soundfileì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ì €ì¥
            # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™”
            audio_data = wavs[0].numpy()
            # ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ 2Dì¸ ê²½ìš° 1Dë¡œ ë³€í™˜
            if audio_data.ndim > 1:
                audio_data = audio_data.squeeze()
            # ë°ì´í„° íƒ€ì…ì„ float32ë¡œ ë³€í™˜
            audio_data = audio_data.astype(np.float32)
            # ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
            sample_rate = int(model.autoencoder.sampling_rate)
            
            sf.write(output_path, audio_data, sample_rate, format='WAV', subtype='PCM_16')
            print(f"ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_path}")
        except Exception as e:
            print(f"soundfile ì €ì¥ ì‹¤íŒ¨, torchaudioë¡œ ì‹œë„: {e}")
            try:
                torchaudio.save(output_path, wavs[0], model.autoencoder.sampling_rate)
                print(f"ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_path} (torchaudio ì‚¬ìš©)")
            except Exception as e2:
                print(f"ì˜¤ë””ì˜¤ ì €ì¥ ì‹¤íŒ¨: {e2}")
    
    return wavs[0], model.autoencoder.sampling_rate


def generate_long_text_voice(text, model, speaker_embedding, language, output_path):
    """ê¸´ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ìŒì„± ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í•  (ë§ˆì¹¨í‘œ ê¸°ì¤€)
    sentences = [s.strip() for s in text.split('.') if s.strip()]
    
    print(f"ì´ {len(sentences)}ê°œ ë¬¸ì¥ìœ¼ë¡œ ë¶„í• ")
    
    all_audio = []
    sample_rate = None
    
    for i, sentence in enumerate(sentences):
        if not sentence.endswith('.'):
            sentence += '.'
        
        print(f"[{i+1}/{len(sentences)}] ë¬¸ì¥ ì²˜ë¦¬: '{sentence[:30]}...'")
        
        # ê° ë¬¸ì¥ì— ëŒ€í•œ speaking_rate ê³„ì‚°
        text_length = len(sentence)
        estimated_phonemes = text_length * 1.5
        target_duration = min(max(estimated_phonemes / 15, 3), 15)  # 3-15ì´ˆ ë²”ìœ„
        speaking_rate = estimated_phonemes / target_duration
        speaking_rate = max(min(speaking_rate, 30), 5)
        
        # ì¡°ê±´ë¶€ ìƒì„± ì„¤ì • - ë³´ì´ìŠ¤ í´ë¡œë‹ ìµœì í™”
        cond_dict = make_cond_dict(
            text=sentence,
            speaker=speaker_embedding,
            language=language,
            device=device,
            pitch_std=20.0,  # ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±
            speaking_rate=speaking_rate,
            vqscore_8=[0.78] * 8,  # Gradio ê¸°ë³¸ê°’
            dnsmos_ovrl=4.0,  # Gradio ê¸°ë³¸ê°’
            fmax=22050.0,  # ë³´ì´ìŠ¤ í´ë¡œë‹ì— ìµœì í™”ëœ ì£¼íŒŒìˆ˜
            speaker_noised=False  # ìŠ¤í”¼ì»¤ ë…¸ì´ì¦ˆ ì œê±° ë¹„í™œì„±í™”
        )
        conditioning = model.prepare_conditioning(cond_dict)
        
        # ìŒì„± ìƒì„±
        codes = model.generate(conditioning)
        wavs = model.autoencoder.decode(codes).cpu()
        
        all_audio.append(wavs[0])
        if sample_rate is None:
            sample_rate = model.autoencoder.sampling_rate
    
    # ëª¨ë“  ì˜¤ë””ì˜¤ë¥¼ ì—°ê²°
    if len(all_audio) > 1:
        combined_audio = torch.cat(all_audio, dim=-1)
    else:
        combined_audio = all_audio[0]
    
    # ì˜¤ë””ì˜¤ ì €ì¥
    if output_path:
        try:
            audio_data = combined_audio.numpy()
            if audio_data.ndim > 1:
                audio_data = audio_data.squeeze()
            audio_data = audio_data.astype(np.float32)
            sample_rate = int(sample_rate)
            
            sf.write(output_path, audio_data, sample_rate, format='WAV', subtype='PCM_16')
            print(f"ê¸´ í…ìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_path}")
        except Exception as e:
            print(f"ê¸´ í…ìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    return combined_audio, sample_rate


def generate_voice_for_scripts(scripts_folder, speaker_audio_path=None, language="en-us"):
    """ìŠ¤í¬ë¦½íŠ¸ í´ë”ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ íŒŒì¼ì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    if not os.path.exists(scripts_folder):
        print(f"ìŠ¤í¬ë¦½íŠ¸ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {scripts_folder}")
        return
    
    # ì˜¤ë””ì˜¤ ì €ì¥ í´ë” ìƒì„±
    audio_folder = f"{scripts_folder}_audio"
    os.makedirs(audio_folder, exist_ok=True)
    print(f"ì˜¤ë””ì˜¤ê°€ '{audio_folder}' í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.")
    
    # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ë“¤ ì°¾ê¸°
    script_files = [f for f in os.listdir(scripts_folder) if f.endswith('.txt')]
    script_files.sort()  # íŒŒì¼ëª… ìˆœìœ¼ë¡œ ì •ë ¬
    
    if not script_files:
        print("ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ì´ {len(script_files)}ê°œì˜ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    # ê° ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì²˜ë¦¬
    for i, script_file in enumerate(script_files, 1):
        script_path = os.path.join(scripts_folder, script_file)
        print(f"\n[{i}/{len(script_files)}] {script_file} ì²˜ë¦¬ ì¤‘...")
        
        try:
            # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì½ê¸°
            with open(script_path, 'r', encoding='utf-8') as f:
                script_text = f.read().strip()
            
            if not script_text:
                print(f"ë¹ˆ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼: {script_file}")
                continue
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ëª… ìƒì„±
            audio_filename = script_file.replace('.txt', '.wav')
            audio_path = os.path.join(audio_folder, audio_filename)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬ (ë§¤ 5ê°œ íŒŒì¼ë§ˆë‹¤)
            if i % 5 == 0:
                print("ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...")
                import gc
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            
            # ìŒì„± ìƒì„±
            generate_voice_from_text(
                text=script_text,
                speaker_audio_path=speaker_audio_path,
                language=language,
                output_path=audio_path
            )
            
        except Exception as e:
            print(f"âŒ {script_file} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    print(f"\nğŸ‰ ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ì˜ ìŒì„± ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê²°ê³¼: {audio_folder}")


def extract_text_and_images_from_pdf(pdf_path, slides_dir="slides"):
    """PDF íŒŒì¼ì—ì„œ ê° í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ì €ì¥ëœ ì´ë¯¸ì§€ íŒŒì¼ì„ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜"""
    try:
        import fitz  # PyMuPDF
        
        doc = fitz.open(pdf_path)
        pages_data = []
        
        for page_num in range(doc.page_count):
            page = doc[page_num]
            page_data = {
                'page_number': page_num + 1,
                'text': '',
                'images': []
            }
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = page.get_text()
            page_data['text'] = text
            
            # ì €ì¥ëœ ì´ë¯¸ì§€ íŒŒì¼ ì‚¬ìš©
            try:
                image_path = os.path.join(slides_dir, f"slide_{page_num + 1}.png")
                
                if os.path.exists(image_path):
                    # ì €ì¥ëœ ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì–´ì„œ Base64ë¡œ ì¸ì½”ë”©
                    with open(image_path, "rb") as img_file:
                        img_bytes = img_file.read()
                        base64_image = base64.b64encode(img_bytes).decode('utf-8')
                        page_data['images'].append(base64_image)
                else:
                    print(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
                
            except Exception as e:
                print(f"í˜ì´ì§€ {page_num + 1}ì˜ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
            
            pages_data.append(page_data)
        
        doc.close()
        return pages_data
    
    except Exception as e:
        print(f"PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []


def generate_presentation_script_for_pdf(pdf_path, prompt):
    """PDFì˜ ëª¨ë“  í˜ì´ì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë°œí‘œ ëŒ€ë³¸ì„ ìƒì„±í•˜ê³  ì§€ì •ëœ í´ë”ì— íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    
    # PDF íŒŒì¼ëª…ì—ì„œ í™•ì¥ìë¥¼ ì œê±°í•˜ì—¬ ê¸°ë³¸ ì´ë¦„ ì¶”ì¶œ
    pdf_base_name = os.path.splitext(os.path.basename(pdf_path))[0]
    
    # ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë” ì´ë¦„ ì§€ì •
    output_folder = f"{pdf_base_name}_scripts"
    
    # í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
    os.makedirs(output_folder, exist_ok=True)
    print(f"ê²°ê³¼ê°€ '{output_folder}' í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.")

    # ë¨¼ì € PDF í˜ì´ì§€ë“¤ì„ ì´ë¯¸ì§€ë¡œ ì¶”ì¶œ
    print("ğŸ“Š PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ì¶”ì¶œ ì¤‘...")
    extract_pages_from_pdf(pdf_path, "slides")
    
    # PDFì—ì„œ í˜ì´ì§€ ë°ì´í„° ì¶”ì¶œ (ì €ì¥ëœ ì´ë¯¸ì§€ ì‚¬ìš©)
    pages_data = extract_text_and_images_from_pdf(pdf_path, "slides")
    
    if not pages_data:
        print("PDF íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    total_pages = len(pages_data)
    print(f"ì´ {total_pages} í˜ì´ì§€ì˜ PDF íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    # ê° í˜ì´ì§€ë¥¼ ìˆœíšŒí•˜ë©° ëŒ€ë³¸ ìƒì„±
    for page_data in pages_data:
        page_num = page_data['page_number']
        print(f"\n[{page_num}/{total_pages}] í˜ì´ì§€ ì²˜ë¦¬ ì¤‘...")
        
        text = page_data['text']
        images = page_data['images']

        # ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ (ë‘ ë¬¸ì¥ ë‚´ë¡œ)
        page_prompt = f"ì´ í˜ì´ì§€ì˜ ë‚´ìš©ì„ ë‘ ë¬¸ì¥ ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•˜ëŠ” ë°œí‘œ ëŒ€ë³¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. {prompt}"

        # GPT-4o APIì— í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ í•¨ê»˜ ì „ì†¡
        try:
            content = [
                {"type": "text", "text": f"{page_prompt}\n\n---í˜ì´ì§€ ë‚´ìš©---\n{text}"}
            ]
            
            # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            for img_base64 in images:
                content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{img_base64}"
                    }
                })
            
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": content
                    }
                ],
                max_tokens=200,  # ì§§ì€ ëŒ€ë³¸ì„ ìœ„í•´ í† í° ìˆ˜ ì œí•œ
            )
            
            script_content = response.choices[0].message.content
            
            # ìƒì„±ëœ ëŒ€ë³¸ì„ ì§€ì •ëœ í´ë” ì•ˆì— íŒŒì¼ë¡œ ì €ì¥
            output_filename = f"{pdf_base_name}_page_{page_num}_script.txt"
            output_path = os.path.join(output_folder, output_filename)
            
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(script_content)
            
            print(f"âœ… '{output_path}' íŒŒì¼ ì €ì¥ ì™„ë£Œ.")

        except Exception as e:
            print(f"âŒ {page_num} í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ API ì˜¤ë¥˜ ë°œìƒ: {e}")

    print("\nğŸ‰ ëª¨ë“  í˜ì´ì§€ì˜ ë°œí‘œ ëŒ€ë³¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")



def generate_presentation_script(file_path, prompt, speaker_audio_path=None, language="ko", generate_audio=True):
    """íŒŒì¼ í™•ì¥ìì— ë”°ë¼ PDF ë˜ëŠ” PPTë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ì„ íƒì ìœ¼ë¡œ ìŒì„±ì„ ìƒì„±í•˜ëŠ” í†µí•© í•¨ìˆ˜"""
    
    # íŒŒì¼ í™•ì¥ì í™•ì¸
    file_extension = os.path.splitext(file_path)[1].lower()
    
    if file_extension == '.pdf':
        print("ğŸ“„ PDF íŒŒì¼ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤. PDF ì²˜ë¦¬ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        generate_presentation_script_for_pdf(file_path, prompt)
    else:
        print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_extension}")
        print("ì§€ì›ë˜ëŠ” í˜•ì‹: .pdf")
        return
    
    # ìŠ¤í¬ë¦½íŠ¸ ìƒì„± í›„ ìŒì„± ìƒì„±
    if generate_audio:
        # ìŠ¤í¬ë¦½íŠ¸ í´ë” ê²½ë¡œ ìƒì„±
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        scripts_folder = f"{base_name}_scripts"
        
        if os.path.exists(scripts_folder):
            print(f"\nğŸµ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ìŒì„± ìƒì„± ì‹œì‘...")
            if speaker_audio_path and os.path.exists(speaker_audio_path):
                print(f"ìŠ¤í”¼ì»¤ ì˜¤ë””ì˜¤ ì‚¬ìš©: {speaker_audio_path}")
            else:
                print("ìŠ¤í”¼ì»¤ ì˜¤ë””ì˜¤ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ìŒì„±ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            
            generate_voice_for_scripts(scripts_folder, speaker_audio_path, language)
        else:
            print(f"ìŠ¤í¬ë¦½íŠ¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scripts_folder}")




def extract_pages_from_pdf(pdf_path, output_dir="slides"):
    """PDF íŒŒì¼ì—ì„œ ê° í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (test_img.py ê¸°ë°˜)"""
    try:
        import fitz  # PyMuPDF
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"ğŸ“Š PDF íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {pdf_path}")
        
        # PDF íŒŒì¼ ì—´ê¸°
        pdf_document = fitz.open(pdf_path)
        
        print(f"ì´ {pdf_document.page_count} í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
        
        page_images = []
        
        for page_num in range(pdf_document.page_count):
            # í˜ì´ì§€ ë¡œë“œ
            page = pdf_document.load_page(page_num)
            
            # ë Œë”ë§ì„ ìœ„í•œ ì„¤ì • (dpië¥¼ ë†’ì—¬ ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¡œ ë§Œë“­ë‹ˆë‹¤)
            zoom = 2  # 200% í™•ëŒ€ (200 DPI)
            mat = fitz.Matrix(zoom, zoom)
            
            # í˜ì´ì§€ë¥¼ í”½ì…€ë§µìœ¼ë¡œ ë³€í™˜ (ì´ë¯¸ì§€ ë°ì´í„°)
            pix = page.get_pixmap(matrix=mat)
            
            # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì„¤ì •
            image_path = os.path.join(output_dir, f"slide_{page_num + 1}.png")
            
            # í”½ì…€ë§µì„ PNG íŒŒì¼ë¡œ ì €ì¥
            pix.save(image_path)
            
            page_images.append(image_path)
            print(f"í˜ì´ì§€ {page_num + 1}ì´ {image_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        pdf_document.close()
        print("âœ… ëª¨ë“  í˜ì´ì§€ ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return page_images
        
    except Exception as e:
        print(f"âŒ PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []




    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0


def create_video_from_slide_audio(slide_image, audio_file, output_video, duration):
    """ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ì™€ ì˜¤ë””ì˜¤ë¡œ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    import subprocess
    
    try:
        cmd = [
            'ffmpeg', '-y',  # ë®ì–´ì“°ê¸° í—ˆìš©
            '-loop', '1', '-i', slide_image,  # ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€
            '-i', audio_file,  # ì˜¤ë””ì˜¤ íŒŒì¼
            '-c:v', 'libx264',  # ë¹„ë””ì˜¤ ì½”ë±
            '-t', str(duration),  # ê¸¸ì´
            '-pix_fmt', 'yuv420p',  # í”½ì…€ í¬ë§·
            '-vf', 'scale=1920:1080:force_original_aspect_ratio=increase,crop=1920:1080',  # ë¹„ë””ì˜¤ í•„í„°
            '-c:a', 'aac', '-b:a', '128k',  # ì˜¤ë””ì˜¤ ì½”ë±
            output_video
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            return True
        else:
            print(f"âŒ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {output_video}")
            print(f"ì˜¤ë¥˜: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"âŒ ë¹„ë””ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return False


def create_presentation_video(file_path, create_video=True):
    """ë°œí‘œ ì˜ìƒì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (Python + ffmpeg ì§ì ‘ ì‚¬ìš©)"""
    if not create_video:
        return
    
    print("\nğŸ¬ ë°œí‘œ ì˜ìƒ ìƒì„± ì‹œì‘...")
    
    try:
        # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs("slides", exist_ok=True)
        os.makedirs("output_videos", exist_ok=True)
        
        # ì´ë¯¸ ì¶”ì¶œëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì‚¬ìš©
        print("ğŸ“Š ì €ì¥ëœ í˜ì´ì§€ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì‚¬ìš© ì¤‘...")
        slide_images = []
        slide_num = 1
        while True:
            slide_path = f"slides/slide_{slide_num}.png"
            if os.path.exists(slide_path):
                slide_images.append(slide_path)
                slide_num += 1
            else:
                break
        
        if not slide_images:
            print("âŒ ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨")
            return
        
        # ìŠ¤í¬ë¦½íŠ¸ í´ë” ì°¾ê¸°
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        scripts_folder = f"{base_name}_scripts"
        audio_folder = f"{scripts_folder}_audio"
        
        if not os.path.exists(scripts_folder):
            print(f"âŒ ìŠ¤í¬ë¦½íŠ¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scripts_folder}")
            return
        
        if not os.path.exists(audio_folder):
            print(f"âŒ ì˜¤ë””ì˜¤ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_folder}")
            return
        
        print(f"ğŸ“ ìŠ¤í¬ë¦½íŠ¸ í´ë”: {scripts_folder}")
        print(f"ğŸµ ì˜¤ë””ì˜¤ í´ë”: {audio_folder}")
        
        # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ê°œìˆ˜ í™•ì¸
        script_files = [f for f in os.listdir(scripts_folder) if f.endswith('.txt')]
        script_count = len(script_files)
        print(f"ğŸ“ ì´ {script_count}ê°œì˜ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ë°œê²¬")
        
        # ê° ìŠ¬ë¼ì´ë“œì™€ ìŒì„±ì„ ê°œë³„ ë¹„ë””ì˜¤ë¡œ ë³€í™˜
        created_videos = []
        
        for i in range(1, script_count + 1):
            print(f"ğŸ¥ ìŠ¬ë¼ì´ë“œ {i} ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")
            
            # íŒŒì¼ ê²½ë¡œ ì„¤ì •
            slide_image = f"slides/slide_{i}.png"
            audio_file = os.path.join(audio_folder, f"{base_name}_slide_{i}_script.wav")
            output_video = f"output_videos/video_{i}.mp4"
            
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(slide_image):
                print(f"âŒ ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {slide_image}")
                continue
            
            if not os.path.exists(audio_file):
                print(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file}")
                continue
            
            # ì˜¤ë””ì˜¤ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸°
            duration = get_audio_duration(audio_file)
            if duration == 0:
                print(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê¸¸ì´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file}")
                continue
            
            print(f"   ì˜¤ë””ì˜¤ ê¸¸ì´: {duration}ì´ˆ")
            
            # ë¹„ë””ì˜¤ ìƒì„±
            if create_video_from_slide_audio(slide_image, audio_file, output_video, duration):
                created_videos.append(output_video)
                print(f"âœ… ìŠ¬ë¼ì´ë“œ {i} ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_video}")
            else:
                print(f"âŒ ìŠ¬ë¼ì´ë“œ {i} ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨")
        
        # ëª¨ë“  ë¹„ë””ì˜¤ë¥¼ í•©ì³ì„œ ìµœì¢… íŒŒì¼ ìƒì„±
        if created_videos:
            print("ğŸ”— ëª¨ë“  ë¹„ë””ì˜¤ í•©ì¹˜ëŠ” ì¤‘...")
            
            # ë¹„ë””ì˜¤ íŒŒì¼ ëª©ë¡ ìƒì„±
            video_list_file = "video_list.txt"
            with open(video_list_file, 'w', encoding='utf-8') as f:
                for video in created_videos:
                    f.write(f"file '{video}'\n")
            
            # ìµœì¢… ë¹„ë””ì˜¤ íŒŒì¼ëª… ìƒì„±
            final_video = f"{base_name}_ë°œí‘œì˜ìƒ.mp4"
            
            # ìµœì¢… ë¹„ë””ì˜¤ ìƒì„±
            import subprocess
            cmd = ['ffmpeg', '-y', '-f', 'concat', '-safe', '0', '-i', video_list_file, '-c', 'copy', final_video]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"ğŸ‰ ë°œí‘œ ì˜ìƒ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤: {final_video}")
                
                # íŒŒì¼ í¬ê¸° í™•ì¸
                if os.path.exists(final_video):
                    file_size = os.path.getsize(final_video) / (1024 * 1024)  # MB
                    print(f"ğŸ“ ìµœì¢… íŒŒì¼ í¬ê¸°: {file_size:.1f}MB")
            else:
                print("âŒ ìµœì¢… ë¹„ë””ì˜¤ í•©ì¹˜ê¸° ì‹¤íŒ¨")
                print(f"ì˜¤ë¥˜: {result.stderr}")
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if os.path.exists(video_list_file):
                os.remove(video_list_file)
        else:
            print("âŒ í•©ì¹  ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        print("ğŸ ì˜ìƒ ìƒì„± ì‘ì—… ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ë¹„ë””ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def show_usage_examples():
    """ì‚¬ìš© ì˜ˆì œë¥¼ ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜"""
    print("""
ğŸ¤ Zonos ë³´ì´ìŠ¤ í´ë¡œë‹ ë°œí‘œ ì˜¤ë””ì˜¤ ìƒì„±ê¸°

ğŸ“‹ ê¸°ëŠ¥:
- PDF íŒŒì¼ì—ì„œ í˜ì´ì§€ë³„ë¡œ ê°„ê²°í•œ ë°œí‘œ ëŒ€ë³¸ ìƒì„±
- ë³´ì´ìŠ¤ í´ë¡œë‹ì„ í†µí•œ ê°œì¸í™”ëœ ìŒì„± ìƒì„±
- ìë™ ë°œí‘œ ì˜ìƒ ìƒì„±
- í•œêµ­ì–´ ì§€ì›

ğŸ“ ê²°ê³¼ íŒŒì¼:
- ë°œí‘œìë£Œ_scripts/     # ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸ íŒŒì¼ë“¤
- ë°œí‘œìë£Œ_scripts_audio/ # ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ë“¤
- ë°œí‘œìë£Œ_ë°œí‘œì˜ìƒ.mp4  # ìµœì¢… ë°œí‘œ ì˜ìƒ

ğŸ¯ ì‚¬ìš©ë²•:
1. sample_voice.wav íŒŒì¼ì„ ì¤€ë¹„ (10-30ì´ˆ ê°œì¸ ìŒì„± ìƒ˜í”Œ)
2. PDF íŒŒì¼ì„ ê°™ì€ í´ë”ì— ë°°ì¹˜
3. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
""")


# --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---
if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì œ ë³´ê¸°
    show_usage_examples()
    
    # ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ (PDF)
    file_path = "test.pdf"  # PDF íŒŒì¼
    
    # ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ (ë‘ ë¬¸ì¥ ë‚´ë¡œ)
    user_prompt = "í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
    
    # ë³´ì´ìŠ¤ í´ë¡œë‹ ì„¤ì •
    speaker_audio_path = "sample_voice.wav"  # ìƒ˜í”Œ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
    language = "ko"  # ì–¸ì–´ ì„¤ì •
    generate_audio = True  # ìŒì„± ìƒì„± ì—¬ë¶€
    
    # í†µí•© í•¨ìˆ˜ ì‹¤í–‰ (ìŠ¤í¬ë¦½íŠ¸ ìƒì„± + ìŒì„± ìƒì„±)
    generate_presentation_script(
        file_path=file_path, 
        prompt=user_prompt,
        speaker_audio_path=speaker_audio_path if os.path.exists(speaker_audio_path) else None,
        language=language,
        generate_audio=generate_audio
    )
    
    # ë°œí‘œ ì˜ìƒ ìƒì„± (ì„ íƒì )
    create_video = True  # ì˜ìƒ ìƒì„±ì„ ì›í•˜ì§€ ì•Šìœ¼ë©´ Falseë¡œ ë³€ê²½
    if create_video:
        create_presentation_video(file_path, create_video=True)