import os
import fitz  # PyMuPDF
import base64
from openai import OpenAI
from pptx import Presentation
from pptx.util import Inches
import io
from PIL import Image
import torch
import torchaudio
import soundfile as sf
import numpy as np
from zonos.model import Zonos
from zonos.conditioning import make_cond_dict
from zonos.utils import DEFAULT_DEVICE as device

# 1. API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì•ˆì „í•˜ê²Œ ë¶ˆëŸ¬ì˜¤ê¸°
api_key = os.environ.get("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
client = OpenAI(api_key=api_key)

# Zonos ëª¨ë¸ ì´ˆê¸°í™” (ì „ì—­ ë³€ìˆ˜ë¡œ ê´€ë¦¬)
ZONOS_MODEL = None
SPEAKER_EMBEDDING = None


def initialize_zonos_model(model_name="Zyphra/Zonos-v0.1-transformer"):
    """Zonos ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜"""
    global ZONOS_MODEL
    if ZONOS_MODEL is None:
        print("Zonos ëª¨ë¸ì„ ë¡œë”© ì¤‘...")
        ZONOS_MODEL = Zonos.from_pretrained(model_name, device=device)
        ZONOS_MODEL.requires_grad_(False).eval()
        print("Zonos ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    return ZONOS_MODEL


def load_speaker_embedding(speaker_audio_path):
    """ìƒ˜í”Œ ì˜¤ë””ì˜¤ì—ì„œ ìŠ¤í”¼ì»¤ ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    global SPEAKER_EMBEDDING
    if SPEAKER_EMBEDDING is None and speaker_audio_path:
        print(f"ìŠ¤í”¼ì»¤ ì˜¤ë””ì˜¤ì—ì„œ ì„ë² ë”© ìƒì„± ì¤‘: {speaker_audio_path}")
        try:
            # torchaudioë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ë¡œë“œ (Gradio ë°©ì‹ê³¼ ë™ì¼)
            wav, sampling_rate = torchaudio.load(speaker_audio_path)
            
            # ìŠ¤í”¼ì»¤ ì„ë² ë”© ìƒì„±
            SPEAKER_EMBEDDING = ZONOS_MODEL.make_speaker_embedding(wav, sampling_rate)
            # bfloat16ìœ¼ë¡œ ë³€í™˜ (Gradio ë°©ì‹ê³¼ ë™ì¼)
            SPEAKER_EMBEDDING = SPEAKER_EMBEDDING.to(device, dtype=torch.bfloat16)
            print("ìŠ¤í”¼ì»¤ ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
        except Exception as e:
            print(f"torchaudio ë¡œë”© ì‹¤íŒ¨, soundfileë¡œ ì‹œë„: {e}")
            try:
                # soundfileì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ë¡œë“œ
                wav, sampling_rate = sf.read(speaker_audio_path)
                # numpy ë°°ì—´ì„ torch tensorë¡œ ë³€í™˜
                wav = torch.from_numpy(wav).float()
                # ëª¨ë…¸ ì±„ë„ë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
                if wav.dim() > 1:
                    wav = wav.mean(dim=-1)
                # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
                wav = wav.unsqueeze(0)
                
                SPEAKER_EMBEDDING = ZONOS_MODEL.make_speaker_embedding(wav, sampling_rate)
                SPEAKER_EMBEDDING = SPEAKER_EMBEDDING.to(device, dtype=torch.bfloat16)
                print("ìŠ¤í”¼ì»¤ ì„ë² ë”© ìƒì„± ì™„ë£Œ! (soundfile ì‚¬ìš©)")
            except Exception as e2:
                print(f"soundfileë¡œë„ ë¡œë”© ì‹¤íŒ¨: {e2}")
                return None
    return SPEAKER_EMBEDDING


def generate_voice_from_text(text, speaker_audio_path=None, language="en-us", output_path=None):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = initialize_zonos_model()
    
    # ìŠ¤í”¼ì»¤ ì„ë² ë”© ë¡œë“œ
    if speaker_audio_path:
        speaker_embedding = load_speaker_embedding(speaker_audio_path)
    else:
        speaker_embedding = None
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ì¸ (ë””ë²„ê¹…ìš©)
    print(f"ì²˜ë¦¬í•  ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì")
    
    # ê¸´ í…ìŠ¤íŠ¸ì˜ ê²½ìš° ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬
    if len(text) > 800:
        print(f"ê¸´ í…ìŠ¤íŠ¸ ê°ì§€ ({len(text)}ì). ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        return generate_long_text_voice(text, model, speaker_embedding, language, output_path)
    
    # Gradio ë°©ì‹ì˜ speaking_rate ê³„ì‚°
    text_length = len(text)
    
    # Gradioì—ì„œ ì‚¬ìš©í•˜ëŠ” ê³µì‹: estimated_generation_duration = 30 * len(text) / 400
    # ì´ë¥¼ ì—­ì‚°í•˜ì—¬ speaking_rate ê³„ì‚°
    estimated_duration = 30 * text_length / 400  # Gradio ë°©ì‹
    estimated_duration = max(min(estimated_duration, 30), 5)  # 5-30ì´ˆ ë²”ìœ„ë¡œ ì œí•œ
    
    # speaking_rateëŠ” ì´ˆë‹¹ ìŒì†Œ ìˆ˜ì´ë¯€ë¡œ, í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°
    # í•œêµ­ì–´ì˜ ê²½ìš° ëŒ€ëµì ìœ¼ë¡œ ê¸€ì ìˆ˜ * 1.5 = ìŒì†Œ ìˆ˜
    estimated_phonemes = text_length * 1.5
    speaking_rate = estimated_phonemes / estimated_duration
    
    # speaking_rate ë²”ìœ„ ì œí•œ (5-30)
    speaking_rate = max(min(speaking_rate, 30), 5)
    
    print(f"í…ìŠ¤íŠ¸ ê¸¸ì´: {text_length}ì, ì˜ˆìƒ ê¸¸ì´: {estimated_duration:.1f}ì´ˆ, Speaking rate: {speaking_rate:.1f}")
    
    # ì¡°ê±´ë¶€ ìƒì„± ì„¤ì • - ë³´ì´ìŠ¤ í´ë¡œë‹ ìµœì í™”
    cond_dict = make_cond_dict(
        text=text,
        speaker=speaker_embedding,
        language=language,
        device=device,
        # ë³´ì´ìŠ¤ í´ë¡œë‹ ìµœì í™” íŒŒë¼ë¯¸í„°
        pitch_std=45.0,  # ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± (Gradio ê¸°ë³¸ê°’)
        speaking_rate=speaking_rate,  # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¼ ì¡°ì •
        vqscore_8=[0.78] * 8,  # Gradio ê¸°ë³¸ê°’
        dnsmos_ovrl=4.0,  # Gradio ê¸°ë³¸ê°’
        fmax=22050.0,  # ë³´ì´ìŠ¤ í´ë¡œë‹ì— ìµœì í™”ëœ ì£¼íŒŒìˆ˜
        speaker_noised=False  # ìŠ¤í”¼ì»¤ ë…¸ì´ì¦ˆ ì œê±° ë¹„í™œì„±í™”
    )
    conditioning = model.prepare_conditioning(cond_dict)
    
    # ìŒì„± ìƒì„±
    print(f"ìŒì„± ìƒì„± ì¤‘: '{text[:50]}...'")
    codes = model.generate(conditioning)
    wavs = model.autoencoder.decode(codes).cpu()
    
    # ì˜¤ë””ì˜¤ ì €ì¥
    if output_path:
        try:
            # soundfileì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ì €ì¥
            # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™”
            audio_data = wavs[0].numpy()
            # ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ 2Dì¸ ê²½ìš° 1Dë¡œ ë³€í™˜
            if audio_data.ndim > 1:
                audio_data = audio_data.squeeze()
            # ë°ì´í„° íƒ€ì…ì„ float32ë¡œ ë³€í™˜
            audio_data = audio_data.astype(np.float32)
            # ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
            sample_rate = int(model.autoencoder.sampling_rate)
            
            sf.write(output_path, audio_data, sample_rate, format='WAV', subtype='PCM_16')
            print(f"ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_path}")
        except Exception as e:
            print(f"soundfile ì €ì¥ ì‹¤íŒ¨, torchaudioë¡œ ì‹œë„: {e}")
            try:
                torchaudio.save(output_path, wavs[0], model.autoencoder.sampling_rate)
                print(f"ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_path} (torchaudio ì‚¬ìš©)")
            except Exception as e2:
                print(f"ì˜¤ë””ì˜¤ ì €ì¥ ì‹¤íŒ¨: {e2}")
    
    return wavs[0], model.autoencoder.sampling_rate


def generate_long_text_voice(text, model, speaker_embedding, language, output_path):
    """ê¸´ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ìŒì„± ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í•  (ë§ˆì¹¨í‘œ ê¸°ì¤€)
    sentences = [s.strip() for s in text.split('.') if s.strip()]
    
    print(f"ì´ {len(sentences)}ê°œ ë¬¸ì¥ìœ¼ë¡œ ë¶„í• ")
    
    all_audio = []
    sample_rate = None
    
    for i, sentence in enumerate(sentences):
        if not sentence.endswith('.'):
            sentence += '.'
        
        print(f"[{i+1}/{len(sentences)}] ë¬¸ì¥ ì²˜ë¦¬: '{sentence[:30]}...'")
        
        # ê° ë¬¸ì¥ì— ëŒ€í•œ speaking_rate ê³„ì‚°
        text_length = len(sentence)
        estimated_phonemes = text_length * 1.5
        target_duration = min(max(estimated_phonemes / 15, 3), 15)  # 3-15ì´ˆ ë²”ìœ„
        speaking_rate = estimated_phonemes / target_duration
        speaking_rate = max(min(speaking_rate, 30), 5)
        
        # ì¡°ê±´ë¶€ ìƒì„± ì„¤ì • - ë³´ì´ìŠ¤ í´ë¡œë‹ ìµœì í™”
        cond_dict = make_cond_dict(
            text=sentence,
            speaker=speaker_embedding,
            language=language,
            device=device,
            pitch_std=20.0,  # ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±
            speaking_rate=speaking_rate,
            vqscore_8=[0.78] * 8,  # Gradio ê¸°ë³¸ê°’
            dnsmos_ovrl=4.0,  # Gradio ê¸°ë³¸ê°’
            fmax=22050.0,  # ë³´ì´ìŠ¤ í´ë¡œë‹ì— ìµœì í™”ëœ ì£¼íŒŒìˆ˜
            speaker_noised=False  # ìŠ¤í”¼ì»¤ ë…¸ì´ì¦ˆ ì œê±° ë¹„í™œì„±í™”
        )
        conditioning = model.prepare_conditioning(cond_dict)
        
        # ìŒì„± ìƒì„±
        codes = model.generate(conditioning)
        wavs = model.autoencoder.decode(codes).cpu()
        
        all_audio.append(wavs[0])
        if sample_rate is None:
            sample_rate = model.autoencoder.sampling_rate
    
    # ëª¨ë“  ì˜¤ë””ì˜¤ë¥¼ ì—°ê²°
    if len(all_audio) > 1:
        combined_audio = torch.cat(all_audio, dim=-1)
    else:
        combined_audio = all_audio[0]
    
    # ì˜¤ë””ì˜¤ ì €ì¥
    if output_path:
        try:
            audio_data = combined_audio.numpy()
            if audio_data.ndim > 1:
                audio_data = audio_data.squeeze()
            audio_data = audio_data.astype(np.float32)
            sample_rate = int(sample_rate)
            
            sf.write(output_path, audio_data, sample_rate, format='WAV', subtype='PCM_16')
            print(f"ê¸´ í…ìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_path}")
        except Exception as e:
            print(f"ê¸´ í…ìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    return combined_audio, sample_rate


def generate_voice_for_scripts(scripts_folder, speaker_audio_path=None, language="en-us"):
    """ìŠ¤í¬ë¦½íŠ¸ í´ë”ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ íŒŒì¼ì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    if not os.path.exists(scripts_folder):
        print(f"ìŠ¤í¬ë¦½íŠ¸ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {scripts_folder}")
        return
    
    # ì˜¤ë””ì˜¤ ì €ì¥ í´ë” ìƒì„±
    audio_folder = f"{scripts_folder}_audio"
    os.makedirs(audio_folder, exist_ok=True)
    print(f"ì˜¤ë””ì˜¤ê°€ '{audio_folder}' í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.")
    
    # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ë“¤ ì°¾ê¸°
    script_files = [f for f in os.listdir(scripts_folder) if f.endswith('.txt')]
    script_files.sort()  # íŒŒì¼ëª… ìˆœìœ¼ë¡œ ì •ë ¬
    
    if not script_files:
        print("ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ì´ {len(script_files)}ê°œì˜ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    # ê° ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì²˜ë¦¬
    for i, script_file in enumerate(script_files, 1):
        script_path = os.path.join(scripts_folder, script_file)
        print(f"\n[{i}/{len(script_files)}] {script_file} ì²˜ë¦¬ ì¤‘...")
        
        try:
            # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì½ê¸°
            with open(script_path, 'r', encoding='utf-8') as f:
                script_text = f.read().strip()
            
            if not script_text:
                print(f"ë¹ˆ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼: {script_file}")
                continue
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ëª… ìƒì„±
            audio_filename = script_file.replace('.txt', '.wav')
            audio_path = os.path.join(audio_folder, audio_filename)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬ (ë§¤ 5ê°œ íŒŒì¼ë§ˆë‹¤)
            if i % 5 == 0:
                print("ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...")
                import gc
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            
            # ìŒì„± ìƒì„±
            generate_voice_from_text(
                text=script_text,
                speaker_audio_path=speaker_audio_path,
                language=language,
                output_path=audio_path
            )
            
        except Exception as e:
            print(f"âŒ {script_file} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    print(f"\nğŸ‰ ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ì˜ ìŒì„± ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê²°ê³¼: {audio_folder}")


def extract_text_and_images_from_pdf(pdf_path):
    """PDF íŒŒì¼ì—ì„œ ê° í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        import fitz  # PyMuPDF
        
        doc = fitz.open(pdf_path)
        pages_data = []
        
        for page_num in range(doc.page_count):
            page = doc[page_num]
            page_data = {
                'page_number': page_num + 1,
                'text': '',
                'images': []
            }
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = page.get_text()
            page_data['text'] = text
            
            # í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ Base64ë¡œ ì¸ì½”ë”©
            try:
                # ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                zoom = 2  # 200% í™•ëŒ€ (200 DPI)
                mat = fitz.Matrix(zoom, zoom)
                pix = page.get_pixmap(matrix=mat)
                
                # ì´ë¯¸ì§€ë¥¼ bytesë¡œ ë³€í™˜
                img_bytes = pix.tobytes("png")
                
                # Base64ë¡œ ì¸ì½”ë”©
                base64_image = base64.b64encode(img_bytes).decode('utf-8')
                page_data['images'].append(base64_image)
                
            except Exception as e:
                print(f"í˜ì´ì§€ {page_num + 1}ì˜ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
            
            pages_data.append(page_data)
        
        doc.close()
        return pages_data
    
    except Exception as e:
        print(f"PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []


def generate_presentation_script_for_pdf(pdf_path, prompt):
    """PDFì˜ ëª¨ë“  í˜ì´ì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë°œí‘œ ëŒ€ë³¸ì„ ìƒì„±í•˜ê³  ì§€ì •ëœ í´ë”ì— íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    
    # PDF íŒŒì¼ëª…ì—ì„œ í™•ì¥ìë¥¼ ì œê±°í•˜ì—¬ ê¸°ë³¸ ì´ë¦„ ì¶”ì¶œ
    pdf_base_name = os.path.splitext(os.path.basename(pdf_path))[0]
    
    # ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë” ì´ë¦„ ì§€ì •
    output_folder = f"{pdf_base_name}_scripts"
    
    # í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
    os.makedirs(output_folder, exist_ok=True)
    print(f"ê²°ê³¼ê°€ '{output_folder}' í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.")

    # PDFì—ì„œ í˜ì´ì§€ ë°ì´í„° ì¶”ì¶œ
    pages_data = extract_text_and_images_from_pdf(pdf_path)
    
    if not pages_data:
        print("PDF íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    total_pages = len(pages_data)
    print(f"ì´ {total_pages} í˜ì´ì§€ì˜ PDF íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    # ê° í˜ì´ì§€ë¥¼ ìˆœíšŒí•˜ë©° ëŒ€ë³¸ ìƒì„±
    for page_data in pages_data:
        page_num = page_data['page_number']
        print(f"\n[{page_num}/{total_pages}] í˜ì´ì§€ ì²˜ë¦¬ ì¤‘...")
        
        text = page_data['text']
        images = page_data['images']

        # ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ (ë‘ ë¬¸ì¥ ë‚´ë¡œ)
        page_prompt = f"ì´ í˜ì´ì§€ì˜ ë‚´ìš©ì„ ë‘ ë¬¸ì¥ ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•˜ëŠ” ë°œí‘œ ëŒ€ë³¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. {prompt}"

        # GPT-4o APIì— í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ í•¨ê»˜ ì „ì†¡
        try:
            content = [
                {"type": "text", "text": f"{page_prompt}\n\n---í˜ì´ì§€ ë‚´ìš©---\n{text}"}
            ]
            
            # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            for img_base64 in images:
                content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{img_base64}"
                    }
                })
            
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": content
                    }
                ],
                max_tokens=200,  # ì§§ì€ ëŒ€ë³¸ì„ ìœ„í•´ í† í° ìˆ˜ ì œí•œ
            )
            
            script_content = response.choices[0].message.content
            
            # ìƒì„±ëœ ëŒ€ë³¸ì„ ì§€ì •ëœ í´ë” ì•ˆì— íŒŒì¼ë¡œ ì €ì¥
            output_filename = f"{pdf_base_name}_page_{page_num}_script.txt"
            output_path = os.path.join(output_folder, output_filename)
            
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(script_content)
            
            print(f"âœ… '{output_path}' íŒŒì¼ ì €ì¥ ì™„ë£Œ.")

        except Exception as e:
            print(f"âŒ {page_num} í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ API ì˜¤ë¥˜ ë°œìƒ: {e}")

    print("\nğŸ‰ ëª¨ë“  í˜ì´ì§€ì˜ ë°œí‘œ ëŒ€ë³¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


# def generate_presentation_script_for_pdf(pdf_path, prompt):
#     """PDFì˜ ëª¨ë“  í˜ì´ì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë°œí‘œ ëŒ€ë³¸ì„ ìƒì„±í•˜ê³  ì§€ì •ëœ í´ë”ì— íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
#     
#     # PDF íŒŒì¼ëª…ì—ì„œ í™•ì¥ìë¥¼ ì œê±°í•˜ì—¬ ê¸°ë³¸ ì´ë¦„ ì¶”ì¶œ (ì˜ˆ: "ì¤‘ê°„ë³´ê³ ì„œ ë¯¸íŒ…")
#     pdf_base_name = os.path.splitext(os.path.basename(pdf_path))[0]
#     
#     # ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë” ì´ë¦„ ì§€ì • (ì˜ˆ: "ì¤‘ê°„ë³´ê³ ì„œ ë¯¸íŒ…_scripts")
#     output_folder = f"{pdf_base_name}_scripts"
#     
#     # í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
#     os.makedirs(output_folder, exist_ok=True)
#     print(f"ê²°ê³¼ê°€ '{output_folder}' í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.")

#     try:
#         doc = fitz.open(pdf_path)
#         total_pages = doc.page_count
#         print(f"ì´ {total_pages} í˜ì´ì§€ì˜ PDF íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

#     except Exception as e:
#         print(f"PDF íŒŒì¼ì„ ì—¬ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
#         return

#     # ê° í˜ì´ì§€ë¥¼ ìˆœíšŒí•˜ë©° ëŒ€ë³¸ ìƒì„±
#     for page_num in range(total_pages):
#         current_page = page_num + 1
#         print(f"\n[{current_page}/{total_pages}] í˜ì´ì§€ ì²˜ë¦¬ ì¤‘...")
#         
#         page = doc[page_num]

#         # 1. í˜„ì¬ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
#         text = page.get_text()

#         # 2. í˜„ì¬ í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ ë° Base64 ì¸ì½”ë”©
#         pix = page.get_pixmap()
#         image_bytes = pix.tobytes("png")
#         base64_image = base64.b64encode(image_bytes).decode('utf-8')

#         # 3. GPT-4o APIì— í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ í•¨ê»˜ ì „ì†¡
#         try:
#             response = client.chat.completions.create(
#                 model="gpt-4o",
#                 messages=[
#                     {
#                         "role": "user",
#                         "content": [
#                             {"type": "text", "text": f"ì´ê²ƒì€ ì „ì²´ ë°œí‘œ ìë£Œ ì¤‘ {current_page}ë²ˆì§¸ í˜ì´ì§€ì…ë‹ˆë‹¤. {prompt}\n\n---ì¶”ì¶œëœ í…ìŠ¤íŠ¸---\n{text}"},
#                             {
#                                 "type": "image_url",
#                                 "image_url": {
#                                     "url": f"data:image/png;base64,{base64_image}"
#                                 }
#                             }
#                         ]
#                     }
#                 ],
#                 max_tokens=1000,
#             )
#             
#             script_content = response.choices[0].message.content
            
#             # 4. ìƒì„±ëœ ëŒ€ë³¸ì„ ì§€ì •ëœ í´ë” ì•ˆì— íŒŒì¼ë¡œ ì €ì¥
#             output_filename = f"{pdf_base_name}_page_{current_page}_script.txt"
#             output_path = os.path.join(output_folder, output_filename)
#             
#             with open(output_path, "w", encoding="utf-8") as f:
#                 f.write(script_content)
#             
#             print(f"âœ… '{output_path}' íŒŒì¼ ì €ì¥ ì™„ë£Œ.")

#         except Exception as e:
#             print(f"âŒ {current_page} í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ API ì˜¤ë¥˜ ë°œìƒ: {e}")

#     doc.close()
#     print("\nğŸ‰ ëª¨ë“  í˜ì´ì§€ì˜ ë°œí‘œ ëŒ€ë³¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


def generate_presentation_script(file_path, prompt, speaker_audio_path=None, language="ko", generate_audio=True):
    """íŒŒì¼ í™•ì¥ìì— ë”°ë¼ PDF ë˜ëŠ” PPTë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ì„ íƒì ìœ¼ë¡œ ìŒì„±ì„ ìƒì„±í•˜ëŠ” í†µí•© í•¨ìˆ˜"""
    
    # íŒŒì¼ í™•ì¥ì í™•ì¸
    file_extension = os.path.splitext(file_path)[1].lower()
    
    if file_extension == '.pdf':
        print("ğŸ“„ PDF íŒŒì¼ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤. PDF ì²˜ë¦¬ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        generate_presentation_script_for_pdf(file_path, prompt)
    else:
        print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_extension}")
        print("ì§€ì›ë˜ëŠ” í˜•ì‹: .pdf")
        return
    
    # ìŠ¤í¬ë¦½íŠ¸ ìƒì„± í›„ ìŒì„± ìƒì„±
    if generate_audio:
        # ìŠ¤í¬ë¦½íŠ¸ í´ë” ê²½ë¡œ ìƒì„±
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        scripts_folder = f"{base_name}_scripts"
        
        if os.path.exists(scripts_folder):
            print(f"\nğŸµ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ìŒì„± ìƒì„± ì‹œì‘...")
            if speaker_audio_path and os.path.exists(speaker_audio_path):
                print(f"ìŠ¤í”¼ì»¤ ì˜¤ë””ì˜¤ ì‚¬ìš©: {speaker_audio_path}")
            else:
                print("ìŠ¤í”¼ì»¤ ì˜¤ë””ì˜¤ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ìŒì„±ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            
            generate_voice_for_scripts(scripts_folder, speaker_audio_path, language)
        else:
            print(f"ìŠ¤í¬ë¦½íŠ¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scripts_folder}")




def extract_pages_from_pdf(pdf_path, output_dir="slides"):
    """PDF íŒŒì¼ì—ì„œ ê° í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (test_img.py ê¸°ë°˜)"""
    try:
        import fitz  # PyMuPDF
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"ğŸ“Š PDF íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {pdf_path}")
        
        # PDF íŒŒì¼ ì—´ê¸°
        pdf_document = fitz.open(pdf_path)
        
        print(f"ì´ {pdf_document.page_count} í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
        
        page_images = []
        
        for page_num in range(pdf_document.page_count):
            # í˜ì´ì§€ ë¡œë“œ
            page = pdf_document.load_page(page_num)
            
            # ë Œë”ë§ì„ ìœ„í•œ ì„¤ì • (dpië¥¼ ë†’ì—¬ ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¡œ ë§Œë“­ë‹ˆë‹¤)
            zoom = 2  # 200% í™•ëŒ€ (200 DPI)
            mat = fitz.Matrix(zoom, zoom)
            
            # í˜ì´ì§€ë¥¼ í”½ì…€ë§µìœ¼ë¡œ ë³€í™˜ (ì´ë¯¸ì§€ ë°ì´í„°)
            pix = page.get_pixmap(matrix=mat)
            
            # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì„¤ì •
            image_path = os.path.join(output_dir, f"slide_{page_num + 1}.png")
            
            # í”½ì…€ë§µì„ PNG íŒŒì¼ë¡œ ì €ì¥
            pix.save(image_path)
            
            page_images.append(image_path)
            print(f"í˜ì´ì§€ {page_num + 1}ì´ {image_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        pdf_document.close()
        print("âœ… ëª¨ë“  í˜ì´ì§€ ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return page_images
        
    except Exception as e:
        print(f"âŒ PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []




def convert_ppt_to_images_alternative(ppt_path, output_dir):
    """LibreOfficeê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ëŒ€ì²´ ë°©ë²•"""
    try:
        print("ğŸ”„ ëŒ€ì²´ ë°©ë²•ìœ¼ë¡œ ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        
        from pptx import Presentation
        from PIL import Image, ImageDraw, ImageFont
        
        prs = Presentation(ppt_path)
        print(f"ì´ {len(prs.slides)}ê°œ ìŠ¬ë¼ì´ë“œ ë°œê²¬")
        
        slide_images = []
        
        for slide_num, slide in enumerate(prs.slides, 1):
            print(f"ìŠ¬ë¼ì´ë“œ {slide_num} ì²˜ë¦¬ ì¤‘...")
            
            # ìŠ¬ë¼ì´ë“œë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (í…ìŠ¤íŠ¸ ê¸°ë°˜ì´ì§€ë§Œ ë” ë‚˜ì€ ë ˆì´ì•„ì›ƒ)
            slide_image = create_enhanced_slide_image(slide)
            
            if slide_image:
                # ì´ë¯¸ì§€ ì €ì¥
                output_path = os.path.join(output_dir, f"slide_{slide_num}.png")
                slide_image.save(output_path, "PNG")
                slide_images.append(output_path)
                print(f"ì €ì¥ ì™„ë£Œ: {output_path}")
            else:
                print(f"âŒ ìŠ¬ë¼ì´ë“œ {slide_num} ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨")
        
        return slide_images
        
    except Exception as e:
        print(f"âŒ ëŒ€ì²´ ë°©ë²• ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
        return []


def slide_to_actual_image(slide):
    """ìŠ¬ë¼ì´ë“œë¥¼ ì‹¤ì œ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (LibreOffice ì‚¬ìš©)"""
    try:
        import subprocess
        import tempfile
        import os
        from PIL import Image
        
        # ì„ì‹œ íŒŒì¼ ìƒì„±
        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:
            temp_path = tmp_file.name
        
        # LibreOfficeë¥¼ ì‚¬ìš©í•´ì„œ ìŠ¬ë¼ì´ë“œë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        # ì´ ë°©ë²•ì€ ì‹¤ì œ ìŠ¬ë¼ì´ë“œì˜ ëª¨ë“  ìš”ì†Œë¥¼ í¬í•¨í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±
        try:
            # LibreOffice ëª…ë ¹ì–´ë¡œ ìŠ¬ë¼ì´ë“œë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            cmd = [
                'libreoffice', '--headless', '--convert-to', 'png',
                '--outdir', os.path.dirname(temp_path),
                '--', temp_path
            ]
            
            # ì´ ë°©ë²•ì€ ë³µì¡í•˜ë¯€ë¡œ, ë” ê°„ë‹¨í•œ ë°©ë²• ì‚¬ìš©
            # ì‹¤ì œë¡œëŠ” python-pptxë¡œëŠ” ì™„ì „í•œ ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ì¶”ì¶œì´ ì œí•œì 
            # ëŒ€ì‹  í…ìŠ¤íŠ¸ì™€ ê¸°ë³¸ ë ˆì´ì•„ì›ƒì„ í¬í•¨í•œ ì´ë¯¸ì§€ ìƒì„±
            
            return create_slide_image_with_layout(slide)
            
        except Exception as e:
            print(f"LibreOffice ë³€í™˜ ì‹¤íŒ¨, ëŒ€ì²´ ë°©ë²• ì‚¬ìš©: {e}")
            return create_slide_image_with_layout(slide)
            
    except Exception as e:
        print(f"ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
        return None


def create_slide_image_with_layout(slide):
    """ìŠ¬ë¼ì´ë“œì˜ ë ˆì´ì•„ì›ƒì„ ê³ ë ¤í•œ ì´ë¯¸ì§€ ìƒì„± (í…ŒìŠ¤íŠ¸ ì™„ë£Œëœ ë²„ì „)"""
    try:
        from PIL import Image, ImageDraw, ImageFont
        
        # í‘œì¤€ ìŠ¬ë¼ì´ë“œ í¬ê¸° (16:9)
        slide_width = 1920
        slide_height = 1080
        
        # ì´ë¯¸ì§€ ìƒì„± (í°ìƒ‰ ë°°ê²½)
        img = Image.new('RGB', (slide_width, slide_height), 'white')
        draw = ImageDraw.Draw(img)
        
        # í°íŠ¸ ì„¤ì •
        try:
            title_font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 48)
            body_font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 32)
        except:
            title_font = ImageFont.load_default()
            body_font = ImageFont.load_default()
        
        y_position = 120
        margin = 120
        
        # ìŠ¬ë¼ì´ë“œì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ë ˆì´ì•„ì›ƒì— ë§ê²Œ ê·¸ë¦¬ê¸°
        for i, shape in enumerate(slide.shapes):
            if hasattr(shape, "text") and shape.text.strip():
                text = shape.text.strip()
                
                # ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ëŠ” ì œëª©ìœ¼ë¡œ ì²˜ë¦¬
                if i == 0:
                    font = title_font
                    color = 'darkblue'
                    y_spacing = 60
                else:
                    font = body_font
                    color = 'black'
                    y_spacing = 40
                
                lines = text.split('\n')
                for line in lines:
                    if line.strip():
                        # í…ìŠ¤íŠ¸ê°€ í™”ë©´ì„ ë„˜ì§€ ì•Šë„ë¡ ì²˜ë¦¬
                        if len(line) > 50:
                            words = line.split()
                            current_line = ""
                            for word in words:
                                if len(current_line + " " + word) <= 50:
                                    current_line += " " + word if current_line else word
                                else:
                                    if current_line:
                                        draw.text((margin, y_position), current_line.strip(), fill=color, font=font)
                                        y_position += y_spacing
                                    current_line = word
                            if current_line:
                                draw.text((margin, y_position), current_line.strip(), fill=color, font=font)
                                y_position += y_spacing
                        else:
                            draw.text((margin, y_position), line.strip(), fill=color, font=font)
                            y_position += y_spacing
                        
                        # ìŠ¬ë¼ì´ë“œ ë†’ì´ë¥¼ ë„˜ì§€ ì•Šë„ë¡ ì œí•œ
                        if y_position > slide_height - 100:
                            break
        
        return img
        
    except Exception as e:
        print(f"ìŠ¬ë¼ì´ë“œ ë ˆì´ì•„ì›ƒ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return None


def slide_to_image_python(slide, slide_width=1920, slide_height=1080):
    """ìŠ¬ë¼ì´ë“œë¥¼ PIL Imageë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ê¸°ë°˜)"""
    from PIL import Image, ImageDraw, ImageFont
    
    # ì•ˆì „í•œ í¬ê¸°ë¡œ ì œí•œ
    slide_width = min(slide_width, 1920)
    slide_height = min(slide_height, 1080)
    
    # ë¹ˆ ì´ë¯¸ì§€ ìƒì„± (í°ìƒ‰ ë°°ê²½)
    img = Image.new('RGB', (slide_width, slide_height), 'white')
    draw = ImageDraw.Draw(img)
    
    # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© (í¬ê¸° ì¡°ì •)
    font_size = max(24, min(48, slide_width // 50))  # í™”ë©´ í¬ê¸°ì— ë§ê²Œ í°íŠ¸ í¬ê¸° ì¡°ì •
    try:
        font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", font_size)
    except:
        try:
            font = ImageFont.truetype("arial.ttf", font_size)
        except:
            font = ImageFont.load_default()
    
    y_position = 80
    margin = 80
    line_height = font_size + 10
    
    # ìŠ¬ë¼ì´ë“œì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ê·¸ë¦¬ê¸°
    all_text = []
    for shape in slide.shapes:
        if hasattr(shape, "text") and shape.text.strip():
            all_text.append(shape.text.strip())
    
    # ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•©ì³ì„œ ì²˜ë¦¬
    combined_text = "\n".join(all_text)
    lines = combined_text.split('\n')
    
    for line in lines:
        if line.strip():
            # í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ì§€ ë„ˆë¹„ë¥¼ ë„˜ì§€ ì•Šë„ë¡ ì²˜ë¦¬
            max_chars = slide_width // (font_size // 2)  # ëŒ€ëµì ì¸ ë¬¸ì ìˆ˜ ê³„ì‚°
            
            if len(line) > max_chars:
                # ê¸´ í…ìŠ¤íŠ¸ëŠ” ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ê¸°
                words = line.split()
                current_line = ""
                for word in words:
                    if len(current_line + " " + word) <= max_chars:
                        current_line += " " + word if current_line else word
                    else:
                        if current_line:
                            draw.text((margin, y_position), current_line.strip(), fill='black', font=font)
                            y_position += line_height
                        current_line = word
                if current_line:
                    draw.text((margin, y_position), current_line.strip(), fill='black', font=font)
                    y_position += line_height
            else:
                draw.text((margin, y_position), line.strip(), fill='black', font=font)
                y_position += line_height
            
            # ìŠ¬ë¼ì´ë“œ ë†’ì´ë¥¼ ë„˜ì§€ ì•Šë„ë¡ ì œí•œ
            if y_position > slide_height - 80:
                break
    
    return img


def get_audio_duration(audio_path):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê¸¸ì´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    import subprocess
    
    try:
        result = subprocess.run([
            'ffprobe', '-v', 'error', '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1', audio_path
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            duration = float(result.stdout.strip())
            return int(duration)  # ì •ìˆ˜ë¡œ ë°˜í™˜
        else:
            print(f"âŒ ì˜¤ë””ì˜¤ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {audio_path}")
            return 0
    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0


def create_video_from_slide_audio(slide_image, audio_file, output_video, duration):
    """ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ì™€ ì˜¤ë””ì˜¤ë¡œ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    import subprocess
    
    try:
        cmd = [
            'ffmpeg', '-y',  # ë®ì–´ì“°ê¸° í—ˆìš©
            '-loop', '1', '-i', slide_image,  # ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€
            '-i', audio_file,  # ì˜¤ë””ì˜¤ íŒŒì¼
            '-c:v', 'libx264',  # ë¹„ë””ì˜¤ ì½”ë±
            '-t', str(duration),  # ê¸¸ì´
            '-pix_fmt', 'yuv420p',  # í”½ì…€ í¬ë§·
            '-vf', 'scale=1920:1080:force_original_aspect_ratio=increase,crop=1920:1080',  # ë¹„ë””ì˜¤ í•„í„°
            '-c:a', 'aac', '-b:a', '128k',  # ì˜¤ë””ì˜¤ ì½”ë±
            output_video
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            return True
        else:
            print(f"âŒ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {output_video}")
            print(f"ì˜¤ë¥˜: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"âŒ ë¹„ë””ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return False


def create_presentation_video(file_path, create_video=True):
    """ë°œí‘œ ì˜ìƒì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (Python + ffmpeg ì§ì ‘ ì‚¬ìš©)"""
    if not create_video:
        return
    
    print("\nğŸ¬ ë°œí‘œ ì˜ìƒ ìƒì„± ì‹œì‘...")
    
    try:
        # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs("slides", exist_ok=True)
        os.makedirs("output_videos", exist_ok=True)
        
        # PDF íŒŒì¼ì—ì„œ í˜ì´ì§€ ì´ë¯¸ì§€ ì¶”ì¶œ
        print("ğŸ“Š PDFì—ì„œ í˜ì´ì§€ ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘...")
        slide_images = extract_pages_from_pdf(file_path)
        
        if not slide_images:
            print("âŒ ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨")
            return
        
        # ìŠ¤í¬ë¦½íŠ¸ í´ë” ì°¾ê¸°
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        scripts_folder = f"{base_name}_scripts"
        audio_folder = f"{scripts_folder}_audio"
        
        if not os.path.exists(scripts_folder):
            print(f"âŒ ìŠ¤í¬ë¦½íŠ¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scripts_folder}")
            return
        
        if not os.path.exists(audio_folder):
            print(f"âŒ ì˜¤ë””ì˜¤ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_folder}")
            return
        
        print(f"ğŸ“ ìŠ¤í¬ë¦½íŠ¸ í´ë”: {scripts_folder}")
        print(f"ğŸµ ì˜¤ë””ì˜¤ í´ë”: {audio_folder}")
        
        # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ê°œìˆ˜ í™•ì¸
        script_files = [f for f in os.listdir(scripts_folder) if f.endswith('.txt')]
        script_count = len(script_files)
        print(f"ğŸ“ ì´ {script_count}ê°œì˜ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ë°œê²¬")
        
        # ê° ìŠ¬ë¼ì´ë“œì™€ ìŒì„±ì„ ê°œë³„ ë¹„ë””ì˜¤ë¡œ ë³€í™˜
        created_videos = []
        
        for i in range(1, script_count + 1):
            print(f"ğŸ¥ ìŠ¬ë¼ì´ë“œ {i} ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")
            
            # íŒŒì¼ ê²½ë¡œ ì„¤ì •
            slide_image = f"slides/slide_{i}.png"
            audio_file = os.path.join(audio_folder, f"{base_name}_slide_{i}_script.wav")
            output_video = f"output_videos/video_{i}.mp4"
            
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(slide_image):
                print(f"âŒ ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {slide_image}")
                continue
            
            if not os.path.exists(audio_file):
                print(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file}")
                continue
            
            # ì˜¤ë””ì˜¤ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸°
            duration = get_audio_duration(audio_file)
            if duration == 0:
                print(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê¸¸ì´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file}")
                continue
            
            print(f"   ì˜¤ë””ì˜¤ ê¸¸ì´: {duration}ì´ˆ")
            
            # ë¹„ë””ì˜¤ ìƒì„±
            if create_video_from_slide_audio(slide_image, audio_file, output_video, duration):
                created_videos.append(output_video)
                print(f"âœ… ìŠ¬ë¼ì´ë“œ {i} ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_video}")
            else:
                print(f"âŒ ìŠ¬ë¼ì´ë“œ {i} ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨")
        
        # ëª¨ë“  ë¹„ë””ì˜¤ë¥¼ í•©ì³ì„œ ìµœì¢… íŒŒì¼ ìƒì„±
        if created_videos:
            print("ğŸ”— ëª¨ë“  ë¹„ë””ì˜¤ í•©ì¹˜ëŠ” ì¤‘...")
            
            # ë¹„ë””ì˜¤ íŒŒì¼ ëª©ë¡ ìƒì„±
            video_list_file = "video_list.txt"
            with open(video_list_file, 'w', encoding='utf-8') as f:
                for video in created_videos:
                    f.write(f"file '{video}'\n")
            
            # ìµœì¢… ë¹„ë””ì˜¤ íŒŒì¼ëª… ìƒì„±
            final_video = f"{base_name}_ë°œí‘œì˜ìƒ.mp4"
            
            # ìµœì¢… ë¹„ë””ì˜¤ ìƒì„±
            import subprocess
            cmd = ['ffmpeg', '-y', '-f', 'concat', '-safe', '0', '-i', video_list_file, '-c', 'copy', final_video]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"ğŸ‰ ë°œí‘œ ì˜ìƒ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤: {final_video}")
                
                # íŒŒì¼ í¬ê¸° í™•ì¸
                if os.path.exists(final_video):
                    file_size = os.path.getsize(final_video) / (1024 * 1024)  # MB
                    print(f"ğŸ“ ìµœì¢… íŒŒì¼ í¬ê¸°: {file_size:.1f}MB")
            else:
                print("âŒ ìµœì¢… ë¹„ë””ì˜¤ í•©ì¹˜ê¸° ì‹¤íŒ¨")
                print(f"ì˜¤ë¥˜: {result.stderr}")
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if os.path.exists(video_list_file):
                os.remove(video_list_file)
        else:
            print("âŒ í•©ì¹  ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        print("ğŸ ì˜ìƒ ìƒì„± ì‘ì—… ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ë¹„ë””ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def show_usage_examples():
    """ì‚¬ìš© ì˜ˆì œë¥¼ ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜"""
    print("""
ğŸ¤ Zonos ë³´ì´ìŠ¤ í´ë¡œë‹ ë°œí‘œ ì˜¤ë””ì˜¤ ìƒì„±ê¸°

ğŸ“‹ ê¸°ëŠ¥:
- PDF íŒŒì¼ì—ì„œ í˜ì´ì§€ë³„ë¡œ ê°„ê²°í•œ ë°œí‘œ ëŒ€ë³¸ ìƒì„±
- ë³´ì´ìŠ¤ í´ë¡œë‹ì„ í†µí•œ ê°œì¸í™”ëœ ìŒì„± ìƒì„±
- ìë™ ë°œí‘œ ì˜ìƒ ìƒì„±
- í•œêµ­ì–´ ì§€ì›

ğŸ“ ê²°ê³¼ íŒŒì¼:
- ë°œí‘œìë£Œ_scripts/     # ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸ íŒŒì¼ë“¤
- ë°œí‘œìë£Œ_scripts_audio/ # ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ë“¤
- ë°œí‘œìë£Œ_ë°œí‘œì˜ìƒ.mp4  # ìµœì¢… ë°œí‘œ ì˜ìƒ

ğŸ¯ ì‚¬ìš©ë²•:
1. sample_voice.wav íŒŒì¼ì„ ì¤€ë¹„ (10-30ì´ˆ ê°œì¸ ìŒì„± ìƒ˜í”Œ)
2. PDF íŒŒì¼ì„ ê°™ì€ í´ë”ì— ë°°ì¹˜
3. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
""")


# --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---
if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì œ ë³´ê¸°
    show_usage_examples()
    
    # ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ (PDF)
    file_path = "ì¤‘ê°„ë³´ê³ ì„œ ë¯¸íŒ….pdf"  # PDF íŒŒì¼
    
    # ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ (ë‘ ë¬¸ì¥ ë‚´ë¡œ)
    user_prompt = "í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
    
    # ë³´ì´ìŠ¤ í´ë¡œë‹ ì„¤ì •
    speaker_audio_path = "sample_voice.wav"  # ìƒ˜í”Œ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
    language = "ko"  # ì–¸ì–´ ì„¤ì •
    generate_audio = True  # ìŒì„± ìƒì„± ì—¬ë¶€
    
    # í†µí•© í•¨ìˆ˜ ì‹¤í–‰ (ìŠ¤í¬ë¦½íŠ¸ ìƒì„± + ìŒì„± ìƒì„±)
    generate_presentation_script(
        file_path=file_path, 
        prompt=user_prompt,
        speaker_audio_path=speaker_audio_path if os.path.exists(speaker_audio_path) else None,
        language=language,
        generate_audio=generate_audio
    )
    
    # ë°œí‘œ ì˜ìƒ ìƒì„± (ì„ íƒì )
    create_video = True  # ì˜ìƒ ìƒì„±ì„ ì›í•˜ì§€ ì•Šìœ¼ë©´ Falseë¡œ ë³€ê²½
    if create_video:
        create_presentation_video(file_path, create_video=True)